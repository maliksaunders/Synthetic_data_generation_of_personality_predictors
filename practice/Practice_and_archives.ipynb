{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Examples for using each of the 6 methods of the sklearn.preprocessing.MinMaxScaler class\n",
    "\n",
    "### Methods of the sklearn.preprocessing.MinMaxScaler class\n",
    "1. fit(X[, y])\tCompute the minimum and maximum to be used for later scaling.\n",
    "2. fit_transform(X[, y])\tFit to data, then transform it.\n",
    "3. get_params([deep])\tGet parameters for this estimator.\n",
    "4. inverse_transform(X)\tUndo the scaling of X according to feature_range.\n",
    "5. set_params(**params)\tSet the parameters of this estimator.\n",
    "6. transform(X)\tScaling features of X according to feature_range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit(X)\n",
    "Computes the minimum and maximum to be used for later scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[ 1 -1  2]\n",
      " [ 2  0  0]\n",
      " [ 0  1 -1]]\n",
      "X.min(axis=0):\n",
      "[ 0 -1 -1]\n",
      "X.max(axis=0):\n",
      "[2 1 2]\n",
      "X_std_num:\n",
      "[[1 0 3]\n",
      " [2 1 1]\n",
      " [0 2 0]]\n",
      "X_std_denom:\n",
      "[2 2 3]\n",
      "X_std:\n",
      "[[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n",
      "X_std_dev_np:\n",
      "1.0657403385139377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data\n",
    "# X = np.array([[1, -1, 2],\n",
    "#               [2, 0, 0],\n",
    "#               [0, 1, -1]])\n",
    "\n",
    "# X = np.array([[1, 2, 3, 4, 5],\n",
    "#               [5, 4, 3, 2, 1],\n",
    "#               [1, 1, 1, 2, 5]])\n",
    "\n",
    "array_1 = [1, -1, 2]\n",
    "array_2 = [2, 0, 0]\n",
    "array_3 = [0, 1, -1]\n",
    "\n",
    "X = np.array([array_1,\n",
    "             array_2,\n",
    "             array_3])\n",
    "\n",
    "print('X:')\n",
    "print(X)\n",
    "X_min_axis_0 = X.min(axis=0)\n",
    "X_max_axis_0 = X.max(axis=0)\n",
    "\n",
    "## X_std is the Standardization of the X Matrix\n",
    "X_std_num = (X - X_min_axis_0)\n",
    "X_std_denom = (X_max_axis_0 - X_min_axis_0)\n",
    "X_std = X_std_num / X_std_denom\n",
    "print('X.min(axis=0):')\n",
    "print(X_min_axis_0)\n",
    "print('X.max(axis=0):')\n",
    "print(X_max_axis_0)\n",
    "print('X_std_num:')\n",
    "print(X_std_num)\n",
    "print('X_std_denom:')\n",
    "print(X_std_denom)\n",
    "print('X_std:')\n",
    "print(X_std)\n",
    "\n",
    "\n",
    "#std_dev_np\n",
    "X_std_dev_np = np.std(X)\n",
    "print('X_std_dev_np:')\n",
    "print(X_std_dev_np)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform(X)\n",
    "Scales the data based on the previously computed min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed:\n",
      " [[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "print(\"Transformed:\\n\", X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit_transform(X)\n",
    "Combines fit and transform in one step (common shortcut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit and Transformed:\n",
      " [[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled_direct = scaler.fit_transform(X)\n",
    "print(\"Fit and Transformed:\\n\", X_scaled_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  inverse_transform(X_scaled)\n",
    "Reverses the scaling back to the original data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Transformed:\n",
      " [[ 1. -1.  2.]\n",
      " [ 2.  0.  0.]\n",
      " [ 0.  1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "X_original = scaler.inverse_transform(X_scaled_direct)\n",
    "print(\"Inverse Transformed:\\n\", X_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_params()\n",
    "Returns the parameters used in the scaler instance (e.g., feature_range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler Parameters:\n",
      " {'clip': False, 'copy': True, 'feature_range': (0, 1)}\n"
     ]
    }
   ],
   "source": [
    "params = scaler.get_params()\n",
    "print(\"Scaler Parameters:\\n\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set_params(**params)\n",
    "Updates the parameters of the scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed with custom range (-1, 1):\n",
      " [[ 0.         -1.          1.        ]\n",
      " [ 1.          0.         -0.33333333]\n",
      " [-1.          1.         -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "scaler.set_params(feature_range=(-1, 1))\n",
    "X_scaled_custom_range = scaler.fit_transform(X)\n",
    "print(\"Transformed with custom range (-1, 1):\\n\", X_scaled_custom_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare & Contrast CTGAN to basic GAN (Generative Adversarial Networks)\n",
    "\n",
    "### Core Difference:\n",
    "The fundamental difference lies in their architecture and the way they handle tabular data, especially categorical features.\n",
    "\n",
    "- CTGAN: Is explicitly designed for tabular data. It incorporates techniques to handle categorical variables effectively and to learn the underlying distributions of the data more accurately. It often uses a conditional generator that takes both random noise and information about the discrete columns as input. Â  \n",
    "- Basic GAN: Is a more general generative model originally designed for continuous data like images. When applied directly to tabular data, it typically treats all columns as continuous, which can lead to poor handling of categorical features and potentially unrealistic synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAILED ATTEMPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out rows that are Out-of-Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Filters on synthetic_data\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(25200, 108)\n",
      "50\n",
      "(17654, 108)\n",
      "(15805, 108)\n",
      "(12609, 108)\n",
      "(11372, 108)\n",
      "(7082, 108)\n",
      "(5992, 108)\n",
      "(4074, 108)\n",
      "(3595, 108)\n",
      "(2149, 108)\n",
      "(1653, 108)\n",
      "(1208, 108)\n",
      "(1069, 108)\n",
      "(936, 108)\n",
      "(491, 108)\n",
      "(440, 108)\n",
      "(252, 108)\n",
      "(185, 108)\n",
      "(163, 108)\n",
      "(149, 108)\n",
      "(93, 108)\n",
      "(69, 108)\n",
      "(62, 108)\n",
      "(24, 108)\n",
      "(17, 108)\n",
      "(16, 108)\n",
      "(12, 108)\n",
      "(11, 108)\n",
      "(11, 108)\n",
      "(7, 108)\n",
      "(7, 108)\n",
      "(7, 108)\n",
      "(7, 108)\n",
      "(7, 108)\n",
      "(6, 108)\n",
      "(5, 108)\n",
      "(2, 108)\n",
      "(2, 108)\n",
      "(2, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "(0, 108)\n",
      "\n",
      "\n",
      "******\n",
      "Likert Scale scores\n",
      "Count of loop on likert_cols list:  50\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(25200, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "       EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
      "count   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "mean    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "std     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "min     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "25%     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "50%     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "75%     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "max     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "\n",
      "       OPN8_E  OPN9_E  OPN10_E  screenw  screenh  introelapse  testelapse  \\\n",
      "count     0.0     0.0      0.0      0.0      0.0          0.0         0.0   \n",
      "mean      NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "std       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "min       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "25%       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "50%       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "75%       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "max       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "\n",
      "       endelapse  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
      "count        0.0                   0.0                    0.0  \n",
      "mean         NaN                   NaN                    NaN  \n",
      "std          NaN                   NaN                    NaN  \n",
      "min          NaN                   NaN                    NaN  \n",
      "25%          NaN                   NaN                    NaN  \n",
      "50%          NaN                   NaN                    NaN  \n",
      "75%          NaN                   NaN                    NaN  \n",
      "max          NaN                   NaN                    NaN  \n",
      "\n",
      "[8 rows x 107 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPN9_E</th>\n",
       "      <th>OPN10_E</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EXT1, EXT2, EXT3, EXT4, EXT5, EXT6, EXT7, EXT8, EXT9, EXT10, EST1, EST2, EST3, EST4, EST5, EST6, EST7, EST8, EST9, EST10, AGR1, AGR2, AGR3, AGR4, AGR5, AGR6, AGR7, AGR8, AGR9, AGR10, CSN1, CSN2, CSN3, CSN4, CSN5, CSN6, CSN7, CSN8, CSN9, CSN10, OPN1, OPN2, OPN3, OPN4, OPN5, OPN6, OPN7, OPN8, OPN9, OPN10, EXT1_E, EXT2_E, EXT3_E, EXT4_E, EXT5_E, EXT6_E, EXT7_E, EXT8_E, EXT9_E, EXT10_E, EST1_E, EST2_E, EST3_E, EST4_E, EST5_E, EST6_E, EST7_E, EST8_E, EST9_E, EST10_E, AGR1_E, AGR2_E, AGR3_E, AGR4_E, AGR5_E, AGR6_E, AGR7_E, AGR8_E, AGR9_E, AGR10_E, CSN1_E, CSN2_E, CSN3_E, CSN4_E, CSN5_E, CSN6_E, CSN7_E, CSN8_E, CSN9_E, CSN10_E, OPN1_E, OPN2_E, OPN3_E, OPN4_E, OPN5_E, OPN6_E, OPN7_E, OPN8_E, OPN9_E, OPN10_E, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******\n",
      "Question time\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(25200, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "\n",
      "******\n",
      "Screen size\n",
      "\n",
      "320.0\n",
      "2048.0\n",
      "533.0\n",
      "1200.0\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(25200, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "\n",
      "******\n",
      "introelapse\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(25200, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(0, 108)\n",
      "['EXT1', 'EXT2', 'EXT3', 'EXT4', 'EXT5', 'EXT6', 'EXT7', 'EXT8', 'EXT9', 'EXT10', 'EST1', 'EST2', 'EST3', 'EST4', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10', 'AGR1', 'AGR2', 'AGR3', 'AGR4', 'AGR5', 'AGR6', 'AGR7', 'AGR8', 'AGR9', 'AGR10', 'CSN1', 'CSN2', 'CSN3', 'CSN4', 'CSN5', 'CSN6', 'CSN7', 'CSN8', 'CSN9', 'CSN10', 'OPN1', 'OPN2', 'OPN3', 'OPN4', 'OPN5', 'OPN6', 'OPN7', 'OPN8', 'OPN9', 'OPN10', 'EXT1_E', 'EXT2_E', 'EXT3_E', 'EXT4_E', 'EXT5_E', 'EXT6_E', 'EXT7_E', 'EXT8_E', 'EXT9_E', 'EXT10_E', 'EST1_E', 'EST2_E', 'EST3_E', 'EST4_E', 'EST5_E', 'EST6_E', 'EST7_E', 'EST8_E', 'EST9_E', 'EST10_E', 'AGR1_E', 'AGR2_E', 'AGR3_E', 'AGR4_E', 'AGR5_E', 'AGR6_E', 'AGR7_E', 'AGR8_E', 'AGR9_E', 'AGR10_E', 'CSN1_E', 'CSN2_E', 'CSN3_E', 'CSN4_E', 'CSN5_E', 'CSN6_E', 'CSN7_E', 'CSN8_E', 'CSN9_E', 'CSN10_E', 'OPN1_E', 'OPN2_E', 'OPN3_E', 'OPN4_E', 'OPN5_E', 'OPN6_E', 'OPN7_E', 'OPN8_E', 'OPN9_E', 'OPN10_E', 'screenw', 'screenh', 'introelapse', 'testelapse', 'endelapse', 'country', 'lat_appx_lots_of_err', 'long_appx_lots_of_err']\n",
      "       EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
      "count   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "mean    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "std     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "min     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "25%     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "50%     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "75%     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "max     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  ...   \n",
      "\n",
      "       OPN8_E  OPN9_E  OPN10_E  screenw  screenh  introelapse  testelapse  \\\n",
      "count     0.0     0.0      0.0      0.0      0.0          0.0         0.0   \n",
      "mean      NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "std       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "min       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "25%       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "50%       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "75%       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "max       NaN     NaN      NaN      NaN      NaN          NaN         NaN   \n",
      "\n",
      "       endelapse  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
      "count        0.0                   0.0                    0.0  \n",
      "mean         NaN                   NaN                    NaN  \n",
      "std          NaN                   NaN                    NaN  \n",
      "min          NaN                   NaN                    NaN  \n",
      "25%          NaN                   NaN                    NaN  \n",
      "50%          NaN                   NaN                    NaN  \n",
      "75%          NaN                   NaN                    NaN  \n",
      "max          NaN                   NaN                    NaN  \n",
      "\n",
      "[8 rows x 107 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPN9_E</th>\n",
       "      <th>OPN10_E</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EXT1, EXT2, EXT3, EXT4, EXT5, EXT6, EXT7, EXT8, EXT9, EXT10, EST1, EST2, EST3, EST4, EST5, EST6, EST7, EST8, EST9, EST10, AGR1, AGR2, AGR3, AGR4, AGR5, AGR6, AGR7, AGR8, AGR9, AGR10, CSN1, CSN2, CSN3, CSN4, CSN5, CSN6, CSN7, CSN8, CSN9, CSN10, OPN1, OPN2, OPN3, OPN4, OPN5, OPN6, OPN7, OPN8, OPN9, OPN10, EXT1_E, EXT2_E, EXT3_E, EXT4_E, EXT5_E, EXT6_E, EXT7_E, EXT8_E, EXT9_E, EXT10_E, EST1_E, EST2_E, EST3_E, EST4_E, EST5_E, EST6_E, EST7_E, EST8_E, EST9_E, EST10_E, AGR1_E, AGR2_E, AGR3_E, AGR4_E, AGR5_E, AGR6_E, AGR7_E, AGR8_E, AGR9_E, AGR10_E, CSN1_E, CSN2_E, CSN3_E, CSN4_E, CSN5_E, CSN6_E, CSN7_E, CSN8_E, CSN9_E, CSN10_E, OPN1_E, OPN2_E, OPN3_E, OPN4_E, OPN5_E, OPN6_E, OPN7_E, OPN8_E, OPN9_E, OPN10_E, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print('No Filters on synthetic_data')\n",
    "# synthetic_data_filtered = synthetic_data.copy()\n",
    "# inspect(synthetic_data, 2)\n",
    "\n",
    "# print(len(likert_cols))\n",
    "# count = 0\n",
    "\n",
    "# for item in likert_cols:\n",
    "#     synthetic_data_filtered = synthetic_data_filtered[\n",
    "#         (synthetic_data_filtered[item] >= 1) & (synthetic_data_filtered[item] <= 5)\n",
    "#     ]\n",
    "#     count = count + 1\n",
    "#     print(synthetic_data_filtered.shape)\n",
    "\n",
    "# print(\"\\n\\n******\")\n",
    "# print('Likert Scale scores')\n",
    "# print('Count of loop on likert_cols list: ', count)\n",
    "# inspect(synthetic_data, 2)\n",
    "# inspect(synthetic_data_filtered, 2)\n",
    "# examinePDF(synthetic_data_filtered, 2)\n",
    "\n",
    "# \"\"\"\n",
    "# Time spent on question in milliseconds.... so the min_of_mins of 414.0 (milliseconds) is 0.414 seconds.\n",
    "# Let's make 0.25 seconds the floor.\n",
    "# The max_of_maxes of 2924135.0 milliseconds is 2,924.135 seconds which is 48.735 minutes.\n",
    "# Let's make the max time for a question 1hour = 3,600,000 milliseconds\n",
    "# \"\"\"\n",
    "# question_time_floor = 250\n",
    "# question_time_ceiling = 3600000\n",
    "\n",
    "# for item in time_cols:\n",
    "#     synthetic_data_filtered_2 = synthetic_data_filtered[\n",
    "#         (synthetic_data_filtered[item] >= question_time_floor) & (synthetic_data_filtered[item] <= question_time_ceiling)\n",
    "#     ]\n",
    "\n",
    "# print(\"\\n\\n******\")\n",
    "# print('Question time')\n",
    "# inspect(synthetic_data, 2)\n",
    "# inspect(synthetic_data_filtered, 2)\n",
    "# inspect(synthetic_data_filtered_2, 2)\n",
    "# #examinePDF(synthetic_data_filtered_2, 2)\n",
    "\n",
    "# \"\"\"\n",
    "# Let's keep the min and max for screen width and height the same from the Sample of 63 real data values\n",
    "# \"\"\"\n",
    "# print(\"\\n\\n******\")\n",
    "# print('Screen size\\n')\n",
    "# screenw_min = other_col_meta_data[0][0]\n",
    "# screenw_max = other_col_meta_data[0][1]\n",
    "# screenh_min = other_col_meta_data[1][0]\n",
    "# screenh_max = other_col_meta_data[1][1]\n",
    "# screen_w_h_min_max_list = [screenw_min, screenw_max, screenh_min, screenh_max]\n",
    "# for item in screen_w_h_min_max_list:\n",
    "#     print(item)\n",
    "\n",
    "\n",
    "# synthetic_data_filtered_3 = synthetic_data_filtered_2[\n",
    "#     (synthetic_data_filtered_2[screenw] >= screenw_min) & (synthetic_data_filtered_2[screenw] <= screenw_max) &\n",
    "#     (synthetic_data_filtered_2[screenh] >= screenh_min) & (synthetic_data_filtered_2[screenh] <= screenh_max)\n",
    "# ]\n",
    "\n",
    "# inspect(synthetic_data, 2)\n",
    "# inspect(synthetic_data_filtered, 2)\n",
    "# inspect(synthetic_data_filtered_2, 2)\n",
    "# inspect(synthetic_data_filtered_3, 2)\n",
    "# #examinePDF(synthetic_data_filtered_3, 2)\n",
    "\n",
    "# \"\"\"\n",
    "# Let's keep the min of introelapse to 2.0\n",
    "# \"\"\"\n",
    "# introelapse_min = 2.0\n",
    "# print(\"\\n\\n******\")\n",
    "# print('introelapse')\n",
    "\n",
    "# synthetic_data_filtered_4 = synthetic_data_filtered_3[\n",
    "#     (synthetic_data_filtered_3[introelapse] >= introelapse_min)\n",
    "# ]\n",
    "\n",
    "# inspect(synthetic_data, 2)\n",
    "# inspect(synthetic_data_filtered, 2)\n",
    "# inspect(synthetic_data_filtered_2, 2)\n",
    "# inspect(synthetic_data_filtered_3, 2)\n",
    "# inspect(synthetic_data_filtered_4, 2)\n",
    "    \n",
    "# examinePDF(synthetic_data_filtered_4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CTGAN from 'sdv.tabular' for 'data_pdf_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sdv.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGAN\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Identify categorical columns\u001b[39;00m\n",
      "\u001b[1;32m      5\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sdv.tabular'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sdv.tabular import CTGAN\n",
    "\n",
    "# # Identify categorical columns\n",
    "# categorical_columns = ['country']\n",
    "\n",
    "# # Model inputs\n",
    "# epochs = 100\n",
    "\n",
    "# # Initialize the CTGAN model\n",
    "# ctgan = CTGAN(epochs=epochs) # You can adjust the number of epochs\n",
    "\n",
    "# # Fit the CTGAN model to your real data\n",
    "# ctgan.fit(data_pdf_clean, discrete_columns=categorical_columns)\n",
    "\n",
    "# # Generate synthetic data\n",
    "# num_samples = len(data_pdf_clean) * 2 # Generate twice the number of real samples\n",
    "# print(\"Number of samples:\")\n",
    "# print(num_samples)\n",
    "# synthetic_data = ctgan.sample(num_samples)\n",
    "\n",
    "# # Print the first few rows of the synthetic data\n",
    "# # print(\"First 5 rows of synthetic data:\")\n",
    "# # print(synthetic_data.head())\n",
    "\n",
    "# ##Display Synthetic Data Frame\n",
    "# inspect(synthetic_data, 3)\n",
    "# print(synthetic_data.describe())\n",
    "# display(synthetic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bound Columns with an **Inverse Transformation and Applying Bounds After Generation**:\n",
    "\n",
    "- All Likert Scale questions to be between 1 and 5\n",
    "- 'screenw' and 'screenh'\n",
    "- 'introelapse', 'testelapse', 'endelapse',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use from sdv.tabular import CTGANSynthesizer instead of from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sdv.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##Define Constraints for CTGANSynthesizer\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import sdv\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sdv\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGANSynthesizer\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sdv.tabular'"
     ]
    }
   ],
   "source": [
    "# ##Define Constraints for CTGANSynthesizer\n",
    "# # import sdv\n",
    "# print(sdv.__version__)\n",
    "\n",
    "# from sdv.tabular import CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TypeVar' from 'typing_extensions' (/Users/maliksaunders/opt/anaconda3/lib/python3.9/site-packages/typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from sklearn.preprocessing import MinMaxScaler\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from ctgan import CTGAN\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGANSynthesizer\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sdv/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attrgetter\n",
      "\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n",
      "\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[1;32m     19\u001b[0m     constraints,\n",
      "\u001b[1;32m     20\u001b[0m     data_processing,\n",
      "\u001b[1;32m     21\u001b[0m     datasets,\n",
      "\u001b[1;32m     22\u001b[0m     evaluation,\n",
      "\u001b[1;32m     23\u001b[0m     io,\n",
      "\u001b[1;32m     24\u001b[0m     lite,\n",
      "\u001b[1;32m     25\u001b[0m     logging,\n",
      "\u001b[1;32m     26\u001b[0m     metadata,\n",
      "\u001b[1;32m     27\u001b[0m     metrics,\n",
      "\u001b[1;32m     28\u001b[0m     multi_table,\n",
      "\u001b[1;32m     29\u001b[0m     sampling,\n",
      "\u001b[1;32m     30\u001b[0m     sequential,\n",
      "\u001b[1;32m     31\u001b[0m     single_table,\n",
      "\u001b[1;32m     32\u001b[0m     version,\n",
      "\u001b[1;32m     33\u001b[0m     utils,\n",
      "\u001b[1;32m     34\u001b[0m )\n",
      "\u001b[1;32m     36\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstraints\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_processing\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutils\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     52\u001b[0m ]\n",
      "\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_addon_target\u001b[39m(addon_path_name):\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sdv/lite/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"SDV lite package that contains model presets.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SingleTablePreset\n",
      "\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingleTablePreset\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sdv/lite/single_table.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcloudpickle\u001b[39;00m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metadata\n",
      "\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianCopulaSynthesizer\n",
      "\u001b[1;32m     13\u001b[0m LOGGER \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;32m     15\u001b[0m FAST_ML_PRESET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAST_ML\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sdv/single_table/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Synthesizers for Single Table data.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcopulagan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CopulaGANSynthesizer\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcopulas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianCopulaSynthesizer\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctgan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGANSynthesizer, TVAESynthesizer\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sdv/single_table/copulagan.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrdt\u001b[39;00m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcopulas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianCopulaSynthesizer\n",
      "\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctgan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGANSynthesizer\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[1;32m     11\u001b[0m     validate_numerical_distributions,\n",
      "\u001b[1;32m     12\u001b[0m     warn_missing_numerical_distributions,\n",
      "\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[1;32m     15\u001b[0m LOGGER \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sdv/single_table/ctgan.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctgan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGAN, TVAE\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/plotly/express/__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n",
      "\u001b[1;32m     11\u001b[0m         \u001b[38;5;124;03m\"\"\"\\\u001b[39;00m\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mPlotly Express requires numpy to be installed. You can install numpy using pip with:\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_imshow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imshow\n",
      "\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chart_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[1;32m     27\u001b[0m     scatter,\n",
      "\u001b[1;32m     28\u001b[0m     scatter_3d,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     65\u001b[0m     density_mapbox,\n",
      "\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[1;32m     70\u001b[0m     set_mapbox_access_token,\n",
      "\u001b[1;32m     71\u001b[0m     defaults,\n",
      "\u001b[1;32m     72\u001b[0m     get_trendline_results,\n",
      "\u001b[1;32m     73\u001b[0m     NO_COLOR,\n",
      "\u001b[1;32m     74\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/plotly/express/_imshow.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_plotly_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasevalidators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColorscaleValidator\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_default_cascade, init_figure, configure_animation_controls\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimshow_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rescale_intensity, _integer_ranges, _integer_types\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnw\u001b[39;00m\n",
      "\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_plotly_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptional_imports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_module\n",
      "\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# back-port of fullmatch from Py3.4+\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m selectors\n",
      "\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stable\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyFrame\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/stable/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n",
      "\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/stable/v1/__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidIntoExprError\n",
      "\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Expr \u001b[38;5;28;01mas\u001b[39;00m NwExpr\n",
      "\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Then \u001b[38;5;28;01mas\u001b[39;00m NwThen\n",
      "\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m When \u001b[38;5;28;01mas\u001b[39;00m NwWhen\n",
      "\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _from_arrow_impl\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/functions.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidOperationError\n",
      "\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Expr\n",
      "\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n",
      "\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_native\n",
      "\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_native\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/series.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries_struct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SeriesStructNamespace\n",
      "\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_native\n",
      "\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntoSeriesT\n",
      "\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _validate_rolling_arguments\n",
      "\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_repr\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/typing.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeVar\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n",
      "\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompliantDataFrame\n",
      "\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompliantLazyFrame\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompliantSeries\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/_compliant/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompliantDataFrame\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompliantLazyFrame\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EagerDataFrame\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/_compliant/dataframe.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compliant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NativeFrameT\n",
      "\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_expression_parsing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_output_names_and_aliases\n",
      "\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_translate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowConvertible\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_translate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictConvertible\n",
      "\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_translate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FromNative\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/narwhals/_translate.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeVar\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _typing_extensions_has_pep_696():\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeVar\n",
      "\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeVar \u001b[38;5;28;01mas\u001b[39;00m _TypeVar\n",
      "\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TypeVar' from 'typing_extensions' (/Users/maliksaunders/opt/anaconda3/lib/python3.9/site-packages/typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from ctgan import CTGAN\n",
    "\n",
    "# ##Scale Likert data columns before training CTGAN\n",
    "# scaler = MinMaxScaler()\n",
    "# data_pdf_clean[likert_cols] = scaler.fit_transform(data_pdf_clean[likert_cols]) ##???Something must be wrong with fit_transform???\n",
    "\n",
    "# #Train CTGAN with Scaled data\n",
    "# epochs = 100\n",
    "# ctgan = CTGAN(epochs=epochs)\n",
    "# ctgan.fit(data_pdf_clean, discrete_columns=categorical_columns)\n",
    "# # Now, generate synthetic data of the same size as the original training data:\n",
    "# num_samples=len(data_pdf_clean)\n",
    "# #num_samples = len(data_pdf_clean) * 200 ## Scaling up samples here somehow distorts distribution of Values\n",
    "# synthetic_scaled = ctgan.sample(num_samples)\n",
    "\n",
    "# inspect(synthetic_scaled, 3)\n",
    "# display(synthetic_scaled)\n",
    "# synthetic_scaled.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Inspection of Pandas DataFrame**\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(63, 108)\n",
      "['EXT1', 'EXT2', 'EXT3', 'EXT4', 'EXT5', 'EXT6', 'EXT7', 'EXT8', 'EXT9', 'EXT10', 'EST1', 'EST2', 'EST3', 'EST4', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10', 'AGR1', 'AGR2', 'AGR3', 'AGR4', 'AGR5', 'AGR6', 'AGR7', 'AGR8', 'AGR9', 'AGR10', 'CSN1', 'CSN2', 'CSN3', 'CSN4', 'CSN5', 'CSN6', 'CSN7', 'CSN8', 'CSN9', 'CSN10', 'OPN1', 'OPN2', 'OPN3', 'OPN4', 'OPN5', 'OPN6', 'OPN7', 'OPN8', 'OPN9', 'OPN10', 'EXT1_E', 'EXT2_E', 'EXT3_E', 'EXT4_E', 'EXT5_E', 'EXT6_E', 'EXT7_E', 'EXT8_E', 'EXT9_E', 'EXT10_E', 'EST1_E', 'EST2_E', 'EST3_E', 'EST4_E', 'EST5_E', 'EST6_E', 'EST7_E', 'EST8_E', 'EST9_E', 'EST10_E', 'AGR1_E', 'AGR2_E', 'AGR3_E', 'AGR4_E', 'AGR5_E', 'AGR6_E', 'AGR7_E', 'AGR8_E', 'AGR9_E', 'AGR10_E', 'CSN1_E', 'CSN2_E', 'CSN3_E', 'CSN4_E', 'CSN5_E', 'CSN6_E', 'CSN7_E', 'CSN8_E', 'CSN9_E', 'CSN10_E', 'OPN1_E', 'OPN2_E', 'OPN3_E', 'OPN4_E', 'OPN5_E', 'OPN6_E', 'OPN7_E', 'OPN8_E', 'OPN9_E', 'OPN10_E', 'screenw', 'screenh', 'introelapse', 'testelapse', 'endelapse', 'country', 'lat_appx_lots_of_err', 'long_appx_lots_of_err']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPN9_E</th>\n",
       "      <th>OPN10_E</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2140</td>\n",
       "      <td>4980</td>\n",
       "      <td>903</td>\n",
       "      <td>591</td>\n",
       "      <td>19</td>\n",
       "      <td>213</td>\n",
       "      <td>10</td>\n",
       "      <td>GB</td>\n",
       "      <td>-14.357633</td>\n",
       "      <td>216.785205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7157</td>\n",
       "      <td>3554</td>\n",
       "      <td>1157</td>\n",
       "      <td>977</td>\n",
       "      <td>51</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>15.025642</td>\n",
       "      <td>196.829831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29225</td>\n",
       "      <td>5050</td>\n",
       "      <td>624</td>\n",
       "      <td>611</td>\n",
       "      <td>31</td>\n",
       "      <td>-130</td>\n",
       "      <td>18</td>\n",
       "      <td>HR</td>\n",
       "      <td>49.798277</td>\n",
       "      <td>211.435933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4383</td>\n",
       "      <td>4456</td>\n",
       "      <td>936</td>\n",
       "      <td>630</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>AU</td>\n",
       "      <td>42.128067</td>\n",
       "      <td>96.524341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5234</td>\n",
       "      <td>3586</td>\n",
       "      <td>1400</td>\n",
       "      <td>571</td>\n",
       "      <td>30</td>\n",
       "      <td>470</td>\n",
       "      <td>13</td>\n",
       "      <td>PT</td>\n",
       "      <td>57.904745</td>\n",
       "      <td>-43.862155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20877</td>\n",
       "      <td>4447</td>\n",
       "      <td>-153</td>\n",
       "      <td>704</td>\n",
       "      <td>11</td>\n",
       "      <td>-31</td>\n",
       "      <td>14</td>\n",
       "      <td>CO</td>\n",
       "      <td>52.427400</td>\n",
       "      <td>75.629390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4332</td>\n",
       "      <td>4392</td>\n",
       "      <td>948</td>\n",
       "      <td>567</td>\n",
       "      <td>45</td>\n",
       "      <td>363</td>\n",
       "      <td>8</td>\n",
       "      <td>JO</td>\n",
       "      <td>58.042447</td>\n",
       "      <td>98.195827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6989</td>\n",
       "      <td>4657</td>\n",
       "      <td>1422</td>\n",
       "      <td>512</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>TR</td>\n",
       "      <td>23.748721</td>\n",
       "      <td>194.110053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6761</td>\n",
       "      <td>1381</td>\n",
       "      <td>1543</td>\n",
       "      <td>775</td>\n",
       "      <td>45</td>\n",
       "      <td>319</td>\n",
       "      <td>28</td>\n",
       "      <td>FR</td>\n",
       "      <td>31.211897</td>\n",
       "      <td>111.686421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3383</td>\n",
       "      <td>3923</td>\n",
       "      <td>923</td>\n",
       "      <td>686</td>\n",
       "      <td>10</td>\n",
       "      <td>378</td>\n",
       "      <td>20</td>\n",
       "      <td>FR</td>\n",
       "      <td>53.453672</td>\n",
       "      <td>77.662701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  OPN9_E  \\\n",
       "0      1     1     1     1     1     1     1     1     1      1  ...    2140   \n",
       "1      1     1     1     1     1     1     1     1     1      1  ...    7157   \n",
       "2      1     1     1     1     1     1     1     1     1      1  ...   29225   \n",
       "3      1     1     1     1     1     1     1     1     1      1  ...    4383   \n",
       "4      1     1     1     1     1     1     1     1     1      1  ...    5234   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...     ...   \n",
       "58     1     1     1     1     1     1     1     1     1      1  ...   20877   \n",
       "59     1     1     1     1     1     1     1     1     1      1  ...    4332   \n",
       "60     1     1     1     1     1     1     1     1     1      1  ...    6989   \n",
       "61     1     1     1     1     1     1     1     1     1      1  ...    6761   \n",
       "62     1     1     1     1     1     1     1     1     2      1  ...    3383   \n",
       "\n",
       "    OPN10_E  screenw  screenh  introelapse  testelapse  endelapse  country  \\\n",
       "0      4980      903      591           19         213         10       GB   \n",
       "1      3554     1157      977           51          97          5       CA   \n",
       "2      5050      624      611           31        -130         18       HR   \n",
       "3      4456      936      630           43          61          7       AU   \n",
       "4      3586     1400      571           30         470         13       PT   \n",
       "..      ...      ...      ...          ...         ...        ...      ...   \n",
       "58     4447     -153      704           11         -31         14       CO   \n",
       "59     4392      948      567           45         363          8       JO   \n",
       "60     4657     1422      512            9          20         18       TR   \n",
       "61     1381     1543      775           45         319         28       FR   \n",
       "62     3923      923      686           10         378         20       FR   \n",
       "\n",
       "    lat_appx_lots_of_err  long_appx_lots_of_err  \n",
       "0             -14.357633             216.785205  \n",
       "1              15.025642             196.829831  \n",
       "2              49.798277             211.435933  \n",
       "3              42.128067              96.524341  \n",
       "4              57.904745             -43.862155  \n",
       "..                   ...                    ...  \n",
       "58             52.427400              75.629390  \n",
       "59             58.042447              98.195827  \n",
       "60             23.748721             194.110053  \n",
       "61             31.211897             111.686421  \n",
       "62             53.453672              77.662701  \n",
       "\n",
       "[63 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPN8_E</th>\n",
       "      <th>OPN9_E</th>\n",
       "      <th>OPN10_E</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.031746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.015873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1862.730159</td>\n",
       "      <td>5455.888889</td>\n",
       "      <td>4272.158730</td>\n",
       "      <td>907.333333</td>\n",
       "      <td>705.698413</td>\n",
       "      <td>69.253968</td>\n",
       "      <td>170.031746</td>\n",
       "      <td>16.222222</td>\n",
       "      <td>40.412478</td>\n",
       "      <td>96.494353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2193.311079</td>\n",
       "      <td>6130.724419</td>\n",
       "      <td>2546.902598</td>\n",
       "      <td>618.653976</td>\n",
       "      <td>169.252973</td>\n",
       "      <td>116.905251</td>\n",
       "      <td>159.127051</td>\n",
       "      <td>7.069800</td>\n",
       "      <td>24.355660</td>\n",
       "      <td>92.465639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2281.000000</td>\n",
       "      <td>-1939.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>-384.000000</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-145.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-15.000944</td>\n",
       "      <td>-94.660984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>2289.500000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>580.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.178995</td>\n",
       "      <td>46.324147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>4332.000000</td>\n",
       "      <td>4127.000000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>50.289184</td>\n",
       "      <td>117.859605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2582.500000</td>\n",
       "      <td>6831.500000</td>\n",
       "      <td>4910.500000</td>\n",
       "      <td>1276.000000</td>\n",
       "      <td>819.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>56.975809</td>\n",
       "      <td>166.502809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8569.000000</td>\n",
       "      <td>29225.000000</td>\n",
       "      <td>15327.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>1189.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>81.835745</td>\n",
       "      <td>224.027779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EXT1  EXT2  EXT3  EXT4  EXT5  EXT6       EXT7  EXT8       EXT9  EXT10  \\\n",
       "count  63.0  63.0  63.0  63.0  63.0  63.0  63.000000  63.0  63.000000   63.0   \n",
       "mean    1.0   1.0   1.0   1.0   1.0   1.0   1.031746   1.0   1.015873    1.0   \n",
       "std     0.0   0.0   0.0   0.0   0.0   0.0   0.176731   0.0   0.125988    0.0   \n",
       "min     1.0   1.0   1.0   1.0   1.0   1.0   1.000000   1.0   1.000000    1.0   \n",
       "25%     1.0   1.0   1.0   1.0   1.0   1.0   1.000000   1.0   1.000000    1.0   \n",
       "50%     1.0   1.0   1.0   1.0   1.0   1.0   1.000000   1.0   1.000000    1.0   \n",
       "75%     1.0   1.0   1.0   1.0   1.0   1.0   1.000000   1.0   1.000000    1.0   \n",
       "max     1.0   1.0   1.0   1.0   1.0   1.0   2.000000   1.0   2.000000    1.0   \n",
       "\n",
       "       ...       OPN8_E        OPN9_E       OPN10_E      screenw      screenh  \\\n",
       "count  ...    63.000000     63.000000     63.000000    63.000000    63.000000   \n",
       "mean   ...  1862.730159   5455.888889   4272.158730   907.333333   705.698413   \n",
       "std    ...  2193.311079   6130.724419   2546.902598   618.653976   169.252973   \n",
       "min    ... -2281.000000  -1939.000000    414.000000  -384.000000   424.000000   \n",
       "25%    ...   514.500000   2289.500000   2928.000000   536.000000   580.500000   \n",
       "50%    ...  1458.000000   4332.000000   4127.000000   946.000000   676.000000   \n",
       "75%    ...  2582.500000   6831.500000   4910.500000  1276.000000   819.000000   \n",
       "max    ...  8569.000000  29225.000000  15327.000000  2409.000000  1189.000000   \n",
       "\n",
       "       introelapse  testelapse  endelapse  lat_appx_lots_of_err  \\\n",
       "count    63.000000   63.000000  63.000000             63.000000   \n",
       "mean     69.253968  170.031746  16.222222             40.412478   \n",
       "std     116.905251  159.127051   7.069800             24.355660   \n",
       "min     -23.000000 -145.000000   3.000000            -15.000944   \n",
       "25%      18.500000   65.500000  11.000000             23.178995   \n",
       "50%      31.000000  157.000000  16.000000             50.289184   \n",
       "75%      45.000000  283.000000  19.000000             56.975809   \n",
       "max     575.000000  550.000000  40.000000             81.835745   \n",
       "\n",
       "       long_appx_lots_of_err  \n",
       "count              63.000000  \n",
       "mean               96.494353  \n",
       "std                92.465639  \n",
       "min               -94.660984  \n",
       "25%                46.324147  \n",
       "50%               117.859605  \n",
       "75%               166.502809  \n",
       "max               224.027779  \n",
       "\n",
       "[8 rows x 107 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###\n",
    "\n",
    "# # Create a copy to avoid modifying the scaled data\n",
    "# synthetic_data = synthetic_scaled.copy()\n",
    "\n",
    "# # Inverse transform the numerical columns\n",
    "# synthetic_data[likert_cols] = scaler.inverse_transform(synthetic_scaled[likert_cols])\n",
    "\n",
    "# # Apply bounds and discretize for rating columns \n",
    "# rating_cols = likert_cols\n",
    "# min_rating = 1\n",
    "# max_rating = 5\n",
    "\n",
    "# for col in rating_cols:\n",
    "#     synthetic_data[col] = synthetic_data[col].round().clip(min_rating, max_rating).astype(int)\n",
    "\n",
    "# # # Apply bounds for other numerical columns if needed (e.g., time measurements)\n",
    "# # time_cols = ['EXT1_E', 'AGR1_E'] # List your time-related columns\n",
    "# # min_time = 0 # Assuming time cannot be negative\n",
    "# # max_time = 10000 # Example maximum time (adjust based on your data)\n",
    "\n",
    "# # for col in time_cols:\n",
    "# #     synthetic_data[col] = synthetic_data[col].clip(min_time, max_time)\n",
    "\n",
    "# # Now 'synthetic_data' contains values within your desired bounds and is discretized for rating columns\n",
    "# inspect(synthetic_data, 3)\n",
    "# display(synthetic_data)\n",
    "# synthetic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GAN (Basic GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Guidelines and Strategies that can help design an effective architecture for tabular GANs\n",
    "\n",
    "1. Input Size and Complexity of Data\n",
    "The number of hidden layer nodes often depends on the complexity and dimensionality of the input data. Tabular data can vary significantly in complexity, with features that can have a wide range of distributions and relationships. In general:\n",
    "- If the input data has fewer features and is relatively simple, fewer hidden nodes may suffice.\n",
    "- If the data is high-dimensional and complex, a larger number of hidden nodes might be necessary to capture the underlying structure.\n",
    "\n",
    "\n",
    "2. Progressive Layer Sizes\n",
    "In many GAN architectures, a common practice is to progressively increase (or decrease) the number of nodes in hidden layers as you move deeper into the network. For example, you might start with a layer size similar to the input layer, then increase the number of nodes in subsequent hidden layers. A typical structure might look like:\n",
    "- Generator: Start with a smaller number of nodes (e.g., 128 or 256) and progressively increase the number of nodes as you move to deeper layers to generate data that matches the complexity of the original input.\n",
    "- Discriminator: Start with a large number of nodes and decrease the size as you move deeper into the network.\n",
    "\n",
    "\n",
    "3. Common Ratios and Heuristics\n",
    "While there's no fixed ratio, a typical approach is to:\n",
    "- Set the number of hidden nodes to be 2 to 4 times the size of the input layer nodes, especially in the initial hidden layers. For example, if you have 10 input features, starting with a hidden layer size of 32 or 64 nodes might be a reasonable approach.\n",
    "- Experiment with decreasing or increasing the size of subsequent layers (e.g., 128 â 64 â 32).\n",
    "\n",
    "\n",
    "4. Regularization\n",
    "As you increase the number of hidden nodes, the risk of overfitting can also increase, especially if your tabular data is not very large. In these cases, it is important to:\n",
    "- Use dropout layers or batch normalization to prevent overfitting and ensure better generalization.\n",
    "- Apply early stopping based on validation performance.\n",
    "\n",
    "\n",
    "5. Empirical Testing and Hyperparameter Tuning\n",
    "GANs can be sensitive to architecture design, and performance will vary based on the specific dataset and task. The best practice is to empirically test different architectures using:\n",
    "- Grid search or random search to experiment with different hidden layer sizes.\n",
    "- Tools like Hyperopt or Optuna for automated hyperparameter optimization.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "There is no fixed \"ideal ratio\" of hidden layer nodes to input layer nodes for tabular GANs. A good rule of thumb is to start with 2â4 times the input layer size for hidden nodes, but the best architecture will depend on the complexity of your data and the nature of your task. Empirical tuning, guided by validation results, will help you find the best architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GANs and PyTorch to create synthetic data \n",
    "\n",
    "Use GANs and PyTorch to create synthetic data from the sample data above (63 rows).\n",
    "\n",
    "#### Define the Generator and Discriminator Models of GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import torch\n",
    "##import torch.nn as nn\n",
    "\n",
    "# ## Original Generator and Discriminator Functions\n",
    "# # Define the Generator model \n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 128),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(256, output_dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         return self.model(z)\n",
    "\n",
    "# # Define the Discriminator model\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 256),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(128, 1),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "## 2nd Generator and Discriminator Functions\n",
    "# Define the Generator model \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Define the Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Models and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim = 131\n",
      "output_dim = 132\n",
      "data_pdf_clean_encoded.shape = (63, 131)\n",
      "data_pdf_clean_encoded.size = 8253\n",
      "type(enumerate(data_pdf_clean_encoded)): <class 'enumerate'>\n",
      "len(list(enumerate(data_pdf_clean_encoded))): 131\n",
      "data_tensor.shape = torch.Size([63, 131])\n",
      "data_tensor.size(0) = 63\n",
      "type(enumerate(data_tensor)): <class 'enumerate'>\n",
      "len(list(enumerate(data_tensor))): 63\n",
      "\n",
      "i= 0 <class 'torch.Tensor'>\n",
      "Length of data= 131\n",
      "data.size(0)= 131\n",
      "\n",
      "i= 1 <class 'torch.Tensor'>\n",
      "Length of data= 131\n",
      "data.size(0)= 131\n",
      "\n",
      "i= 2 <class 'torch.Tensor'>\n",
      "Length of data= 131\n",
      "data.size(0)= 131\n"
     ]
    }
   ],
   "source": [
    "# Dimensions\n",
    "##input_dim = len(predictor_cols)  # Number of features\n",
    "# input_dim = len(data_pdf_clean.columns) # Number of features\n",
    "# output_dim = input_dim + 1  # Features + target\n",
    "\n",
    "input_dim = len(data_pdf_clean_encoded.columns) # Number of features\n",
    "output_dim = input_dim + 1  # Features + target\n",
    "print('input_dim =', input_dim)\n",
    "print('output_dim =', output_dim)\n",
    "\n",
    "## Create Tensor\n",
    "data_np_array = data_pdf_clean_encoded.to_numpy()\n",
    "##data_tensor = torch.from_numpy(data_pdf_clean_encoded.values)\n",
    "data_tensor = torch.tensor(data_pdf_clean_encoded.values)\n",
    "# print('data_pdf_clean.shape =', data_pdf_clean.shape)\n",
    "# print('data_pdf_clean.size =', data_pdf_clean.size)\n",
    "print('data_pdf_clean_encoded.shape =', data_pdf_clean_encoded.shape)\n",
    "print('data_pdf_clean_encoded.size =', data_pdf_clean_encoded.size)\n",
    "print(\n",
    "    'type(enumerate(data_pdf_clean_encoded)):', \n",
    "    type(enumerate(data_pdf_clean_encoded))\n",
    ")\n",
    "print(\n",
    "    'len(list(enumerate(data_pdf_clean_encoded))):', \n",
    "    len(list(enumerate(data_pdf_clean_encoded)))\n",
    ")\n",
    "\n",
    "\"\"\"In PyTorch, .size(0) returns the size of the first \n",
    "dimension of a tensor.\"\"\"\n",
    "print('data_tensor.shape =', data_tensor.shape)\n",
    "##print('data_tensor.size =', data_tensor.size)\n",
    "print('data_tensor.size(0) =', data_tensor.size(0))\n",
    "print(\n",
    "    'type(enumerate(data_tensor)):', \n",
    "    type(enumerate(data_tensor))\n",
    ")\n",
    "print(\n",
    "    'len(list(enumerate(data_tensor))):', \n",
    "    len(list(enumerate(data_tensor)))\n",
    ")\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i, data in enumerate(data_tensor):\n",
    "    print('\\ni=', i, type(data))\n",
    "    print('Length of data=', len(data))\n",
    "    ##print('data.size=', data.size)\n",
    "    print('data.size(0)=', data.size(0))\n",
    "    ##print('data:')\n",
    "    ##print(data)\n",
    "    count = count + 1\n",
    "    if count >= 3:\n",
    "       break\n",
    "\n",
    "# Instantiate models\n",
    "generator = Generator(input_dim=input_dim, output_dim=output_dim)\n",
    "discriminator = Discriminator(input_dim=output_dim)\n",
    "'''\n",
    "Remember that for GANs the number of \"Backfed Input Cell\" is equal\n",
    "to the number of \"Match Input Output Cells\" \n",
    "'''\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.0002\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss() ##Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the GAN\n",
    "\n",
    "- num_epochs: In tabular GANs (Generative Adversarial Networks), an epoch refers to one complete pass through the entire training dataset by both the generator and the discriminator networks.\n",
    "- batch_size: In tabular GANs (Generative Adversarial Networks), the batch size refers to the number of data samples processed together during one forward and backward pass through the network. It is a key parameter in training both the generator and the discriminator networks.\n",
    "- latent_dim: In tabular GANs (Generative Adversarial Networks), the latent dimension refers to the size of the random input vector (often called latent space or noise vector) fed into the generator network. This vector is used by the generator to produce synthetic data that mimics the real tabular data.\n",
    "\n",
    "#### torch.rand()\n",
    "* torch.rand() returns a tensor defined by the variable argument size (sequence of integers defining the shape of the output tensor), containing random numbers from standard normal distribution.\n",
    "    *  size: sequence of integers defining the size of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.\n",
    "    * out: (optional) output tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x131 and 132x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Discriminator loss on real data\u001b[39;00m\n",
      "\u001b[0;32m---> 25\u001b[0m output_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     26\u001b[0m loss_real \u001b[38;5;241m=\u001b[39m criterion(output_real, real_labels)\n",
      "\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Generate fake data\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n",
      "\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x131 and 132x512)"
     ]
    }
   ],
   "source": [
    "# num_epochs = 10000\n",
    "# batch_size = 64\n",
    "# latent_dim = 100  # Dimension of the noise vector\n",
    "\n",
    "num_epochs = 7\n",
    "batch_size = 10\n",
    "latent_dim = 100  # Dimension of the noise vector\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ##for i, data in enumerate(dataloader):\n",
    "    ##for i, data in enumerate(data_pdf_clean_encoded):\n",
    "    for i, data in enumerate(data_tensor):\n",
    "        # Get real data batch\n",
    "        real_data = data\n",
    "        batch_size = real_data.size(0)\n",
    "\n",
    "        # Labels for real and fake data\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Discriminator loss on real data\n",
    "        output_real = discriminator(real_data)\n",
    "        loss_real = criterion(output_real, real_labels)\n",
    "\n",
    "        # Generate fake data\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        fake_data = generator(z)\n",
    "\n",
    "        # Discriminator loss on fake data\n",
    "        output_fake = discriminator(fake_data.detach())\n",
    "        loss_fake = criterion(output_fake, fake_labels)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generator loss\n",
    "        output = discriminator(fake_data)\n",
    "        loss_G = criterion(output, real_labels)  # Want generator to fool the discriminator\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] | Loss D: {loss_D.item()}, Loss G: {loss_G.item()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors vs Vectors\n",
    "\n",
    "- A **vector** is a mathematical object with both magnitude and direction, while a **tensor** is a more generalized concept that can represent quantities with multiple directions, essentially acting as a multi-dimensional vector, meaning it can describe relationships between multiple vectors or quantities in different directions; in simpler terms, a vector is a single-directional quantity, while a tensor can represent interactions in multiple directions simultaneously.\n",
    "- Example: **Force is a vector** (magnitude and direction), while **stress (which describes forces acting in multiple directions on a surface) is a tensor**.\n",
    "- All vectors are usually tensors. But all tensors canât be vectors. This means tensors are more widespread than vectors (https://allthedifferences.com/difference-between-vectors-and-tensor/#:~:text=A%20vector%20is%20a%20one-dimensional%20array%20of%20numbers%2C,%28strictly%20speaking%2C%20though%20mathematicians%20assemble%20tensors%20through%20vectors%29.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1000, latent_dim)\n",
    "synthetic_data = generator(z).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predictor Data Set and Target Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data_pdf_clean = data_pdf_clean_encoded.drop(['EST1'], axis=1)\n",
    "predictor_cols = pred_data_pdf_clean.columns\n",
    "inspect(predictor_cols)\n",
    "\n",
    "target_series = data_pdf_clean_encoded['EST1']\n",
    "inspect(target_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Example for an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand your data - Become One With Your Data!\n",
    "\n",
    "You should always invest time to understand your data. You should be able to answer questions like:\n",
    "1. How many images do I have?\n",
    "2. What's the shape of my image?\n",
    "3. How do my images look like?\n",
    "\n",
    "So let's first answer those questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Images are usually in the [0., 1.] or [0, 255] range, Normalize transform will bring them into [-1, 1] range\n",
    "# It's one of those things somebody figured out experimentally that it works (without special theoretical arguments)\n",
    "# https://github.com/soumith/ganhacks <- you can find more of those hacks here\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((.5,), (.5,))  \n",
    "    ])\n",
    "\n",
    "# MNIST is a super simple, \"hello world\" dataset so it's included in PyTorch.\n",
    "# First time you run this it will download the MNIST dataset and store it in DATA_DIR_PATH\n",
    "# the 'transform' (defined above) will be applied to every single image\n",
    "mnist_dataset = datasets.MNIST(root=DATA_DIR_PATH, train=True, download=True, transform=transform)\n",
    "\n",
    "# Nice wrapper class helps us load images in batches (suitable for GPUs)\n",
    "mnist_data_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Let's answer our questions\n",
    "\n",
    "# Q1: How many images do I have?\n",
    "print(f'Dataset size: {len(mnist_dataset)} images.')\n",
    "\n",
    "num_imgs_to_visualize = 25  # number of images we'll display\n",
    "batch = next(iter(mnist_data_loader))  # take a single batch from the dataset\n",
    "img_batch = batch[0]  # extract only images and ignore the labels (batch[1])\n",
    "img_batch_subset = img_batch[:num_imgs_to_visualize]  # extract only a subset of images\n",
    "\n",
    "# Q2: What's the shape of my image?\n",
    "# format is (B,C,H,W), B - number of images in batch, C - number of channels, H - height, W - width\n",
    "print(f'Image shape {img_batch_subset.shape[1:]}')  # we ignore shape[0] - number of imgs in batch.\n",
    "\n",
    "# Q3: How do my images look like?\n",
    "# Creates a 5x5 grid of images, normalize will bring images from [-1, 1] range back into [0, 1] for display\n",
    "# pad_value is 1. (white) because it's 0. (black) by default but since our background is also black,\n",
    "# we wouldn't see the grid pattern so I set it to 1.\n",
    "grid = make_grid(img_batch_subset, nrow=int(np.sqrt(num_imgs_to_visualize)), normalize=True, pad_value=1.)\n",
    "grid = np.moveaxis(grid.numpy(), 0, 2)  # from CHW -> HWC format that's what matplotlib expects! Get used to this.\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Samples from the MNIST dataset\")\n",
    "plt.imshow(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = datasets.MNIST(root=DATA_DIR_PATH, train=True, download=True)\n",
    "\n",
    "print(type(mnist_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Images are usually in the [0., 1.] or [0, 255] range, Normalize transform will bring them into [-1, 1] range\n",
    "# It's one of those things somebody figured out experimentally that it works (without special theoretical arguments)\n",
    "# https://github.com/soumith/ganhacks <- you can find more of those hacks here\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((.5,), (.5,))  \n",
    "    ])\n",
    "\n",
    "# MNIST is a super simple, \"hello world\" dataset so it's included in PyTorch.\n",
    "# First time you run this it will download the MNIST dataset and store it in DATA_DIR_PATH\n",
    "# the 'transform' (defined above) will be applied to every single image\n",
    "mnist_dataset = datasets.MNIST(root=DATA_DIR_PATH, train=True, download=True, transform=transform)\n",
    "\n",
    "# Nice wrapper class helps us load images in batches (suitable for GPUs)\n",
    "mnist_data_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Let's answer our questions\n",
    "\n",
    "# Q1: How many images do I have?\n",
    "print(f'Dataset size: {len(mnist_dataset)} images.')\n",
    "\n",
    "num_imgs_to_visualize = 25  # number of images we'll display\n",
    "batch = next(iter(mnist_data_loader))  # take a single batch from the dataset\n",
    "img_batch = batch[0]  # extract only images and ignore the labels (batch[1])\n",
    "img_batch_subset = img_batch[:num_imgs_to_visualize]  # extract only a subset of images\n",
    "\n",
    "# Q2: What's the shape of my image?\n",
    "# format is (B,C,H,W), B - number of images in batch, C - number of channels, H - height, W - width\n",
    "print(f'Image shape {img_batch_subset.shape[1:]}')  # we ignore shape[0] - number of imgs in batch.\n",
    "\n",
    "# Q3: How do my images look like?\n",
    "# Creates a 5x5 grid of images, normalize will bring images from [-1, 1] range back into [0, 1] for display\n",
    "# pad_value is 1. (white) because it's 0. (black) by default but since our background is also black,\n",
    "# we wouldn't see the grid pattern so I set it to 1.\n",
    "grid = make_grid(img_batch_subset, nrow=int(np.sqrt(num_imgs_to_visualize)), normalize=True, pad_value=1.)\n",
    "grid = np.moveaxis(grid.numpy(), 0, 2)  # from CHW -> HWC format that's what matplotlib expects! Get used to this.\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Samples from the MNIST dataset\")\n",
    "plt.imshow(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand your model (neural networks)!\n",
    "\n",
    "Let's define the generator and discriminator networks!\n",
    "\n",
    "The original paper used the maxout activation and dropout for regularization (you don't need to understand this). <br/>\n",
    "I'm using `LeakyReLU` instead and `batch normalization` which came after the original paper was published.\n",
    "\n",
    "Those design decisions are inspired by the DCGAN model which came later than the original GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the generator's input vector. Generator will eventually learn how to map these into meaningful images!\n",
    "LATENT_SPACE_DIM = 100\n",
    "\n",
    "\n",
    "# This one will produce a batch of those vectors\n",
    "def get_gaussian_latent_batch(batch_size, device):\n",
    "    return torch.randn((batch_size, LATENT_SPACE_DIM), device=device)\n",
    "\n",
    "\n",
    "# It's cleaner if you define the block like this - bear with me\n",
    "def vanilla_block(in_feat, out_feat, normalize=True, activation=None):\n",
    "    layers = [nn.Linear(in_feat, out_feat)]\n",
    "    if normalize:\n",
    "        layers.append(nn.BatchNorm1d(out_feat))\n",
    "    # 0.2 was used in DCGAN, I experimented with other values like 0.5 didn't notice significant change\n",
    "    layers.append(nn.LeakyReLU(0.2) if activation is None else activation)\n",
    "    return layers\n",
    "\n",
    "\n",
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"Simple 4-layer MLP generative neural network.\n",
    "\n",
    "    By default it works for MNIST size images (28x28).\n",
    "\n",
    "    There are many ways you can construct generator to work on MNIST.\n",
    "    Even without normalization layers it will work ok. Even with 5 layers it will work ok, etc.\n",
    "\n",
    "    It's generally an open-research question on how to evaluate GANs i.e. quantify that \"ok\" statement.\n",
    "\n",
    "    People tried to automate the task using IS (inception score, often used incorrectly), etc.\n",
    "    but so far it always ends up with some form of visual inspection (human in the loop).\n",
    "    \n",
    "    Fancy way of saying you'll have to take a look at the images from your generator and say hey this looks good!\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_shape=(MNIST_IMG_SIZE, MNIST_IMG_SIZE)):\n",
    "        super().__init__()\n",
    "        self.generated_img_shape = img_shape\n",
    "        num_neurons_per_layer = [LATENT_SPACE_DIM, 256, 512, 1024, img_shape[0] * img_shape[1]]\n",
    "\n",
    "        # Now you see why it's nice to define blocks - it's super concise!\n",
    "        # These are pretty much just linear layers followed by LeakyReLU and batch normalization\n",
    "        # Except for the last layer where we exclude batch normalization and we add Tanh (maps images into our [-1, 1] range!)\n",
    "        self.net = nn.Sequential(\n",
    "            *vanilla_block(num_neurons_per_layer[0], num_neurons_per_layer[1]),\n",
    "            *vanilla_block(num_neurons_per_layer[1], num_neurons_per_layer[2]),\n",
    "            *vanilla_block(num_neurons_per_layer[2], num_neurons_per_layer[3]),\n",
    "            *vanilla_block(num_neurons_per_layer[3], num_neurons_per_layer[4], normalize=False, activation=nn.Tanh())\n",
    "        )\n",
    "\n",
    "    def forward(self, latent_vector_batch):\n",
    "        img_batch_flattened = self.net(latent_vector_batch)\n",
    "        # just un-flatten using view into (N, 1, 28, 28) shape for MNIST\n",
    "        return img_batch_flattened.view(img_batch_flattened.shape[0], 1, *self.generated_img_shape)\n",
    "\n",
    "\n",
    "# You can interpret the output from the discriminator as a probability and the question it should\n",
    "# give an answer to is \"hey is this image real?\". If it outputs 1. it's 100% sure it's real. 0.5 - 50% sure, etc.\n",
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"Simple 3-layer MLP discriminative neural network. It should output probability 1. for real images and 0. for fakes.\n",
    "\n",
    "    By default it works for MNIST size images (28x28).\n",
    "\n",
    "    Again there are many ways you can construct discriminator network that would work on MNIST.\n",
    "    You could use more or less layers, etc. Using normalization as in the DCGAN paper doesn't work well though.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_shape=(MNIST_IMG_SIZE, MNIST_IMG_SIZE)):\n",
    "        super().__init__()\n",
    "        num_neurons_per_layer = [img_shape[0] * img_shape[1], 512, 256, 1]\n",
    "\n",
    "        # Last layer is Sigmoid function - basically the goal of the discriminator is to output 1.\n",
    "        # for real images and 0. for fake images and sigmoid is clamped between 0 and 1 so it's perfect.\n",
    "        self.net = nn.Sequential(\n",
    "            *vanilla_block(num_neurons_per_layer[0], num_neurons_per_layer[1], normalize=False),\n",
    "            *vanilla_block(num_neurons_per_layer[1], num_neurons_per_layer[2], normalize=False),\n",
    "            *vanilla_block(num_neurons_per_layer[2], num_neurons_per_layer[3], normalize=False, activation=nn.Sigmoid())\n",
    "        )\n",
    "\n",
    "    def forward(self, img_batch):\n",
    "        img_batch_flattened = img_batch.view(img_batch.shape[0], -1)  # flatten from (N,1,H,W) into (N, HxW)\n",
    "        return self.net(img_batch_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Training\n",
    "\n",
    "**Feel free to skip this entire section** if you just want to use the pre-trained model to generate some new images - which don't exist in the original MNIST dataset and that's the whole magic of GANs!\n",
    "\n",
    "Phew, so far we got familiar with data and our models, awesome work! <br/>\n",
    "But brace yourselves as this is arguable the hardest part. How to actually train your GAN?\n",
    "\n",
    "Let's start with understanding the loss function! We'll be using `BCE (binary cross-entropy loss`), let's see why? <br/>\n",
    "\n",
    "If we input real images into the discriminator we expect it to output 1 (I'm 100% sure that this is a real image). <br/>\n",
    "The further away it is from 1 and the closer it is to 0 the more we should penalize it, as it is making wrong prediction. <br/>\n",
    "So this is how the loss should look like in that case (it's basically `-log(x)`):\n",
    "\n",
    "<img src=\"data/examples/jupyter/cross_entropy_loss.png\" alt=\"BCE loss when true label = 1.\" align=\"left\"/> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BCE loss basically becomes `-log(x)` when it's target (true) label is 1. <br/>\n",
    "\n",
    "Similarly for fake images, the target (true) label is 0 (as we want the discriminator to output 0 for fake images) and we want to penalize the generator if it starts outputing values close to 1. So we basically want to mirror the above loss function and that's just: `-log(1-x)`. <br/>\n",
    "\n",
    "BCE loss basically becomes `-log(1-x)` when it's target (true) label is 0. That's why it perfectly fits the task! <br/>\n",
    "\n",
    "\n",
    "### Training utility functions\n",
    "Let's define some useful utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried SGD for the discriminator, had problems tweaking it - Adam simply works nicely but default lr 1e-3 won't work!\n",
    "# I had to train discriminator more (4 to 1 schedule worked) to get it working with default lr, still got worse results.\n",
    "# 0.0002 and 0.5, 0.999 are from the DCGAN paper it works here nicely!\n",
    "def get_optimizers(d_net, g_net):\n",
    "    d_opt = Adam(d_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_opt = Adam(g_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    return d_opt, g_opt\n",
    "\n",
    "\n",
    "# It's useful to add some metadata when saving your model, it should probably make sense to also add the number of epochs\n",
    "def get_training_state(generator_net, gan_type_name):\n",
    "    training_state = {\n",
    "        \"commit_hash\": git.Repo(search_parent_directories=True).head.object.hexsha,\n",
    "        \"state_dict\": generator_net.state_dict(),\n",
    "        \"gan_type\": gan_type_name\n",
    "    }\n",
    "    return training_state\n",
    "\n",
    "\n",
    "# Makes things useful when you have multiple models\n",
    "class GANType(enum.Enum):\n",
    "    VANILLA = 0\n",
    "\n",
    "\n",
    "# Feel free to ignore this one not important for GAN training. \n",
    "# It just figures out a good binary name so as not to overwrite your older models.\n",
    "def get_available_binary_name(gan_type_enum=GANType.VANILLA):\n",
    "    def valid_binary_name(binary_name):\n",
    "        # First time you see raw f-string? Don't worry the only trick is to double the brackets.\n",
    "        pattern = re.compile(rf'{gan_type_enum.name}_[0-9]{{6}}\\.pth')\n",
    "        return re.fullmatch(pattern, binary_name) is not None\n",
    "\n",
    "    prefix = gan_type_enum.name\n",
    "    # Just list the existing binaries so that we don't overwrite them but write to a new one\n",
    "    valid_binary_names = list(filter(valid_binary_name, os.listdir(BINARIES_PATH)))\n",
    "    if len(valid_binary_names) > 0:\n",
    "        last_binary_name = sorted(valid_binary_names)[-1]\n",
    "        new_suffix = int(last_binary_name.split('.')[0][-6:]) + 1  # increment by 1\n",
    "        return f'{prefix}_{str(new_suffix).zfill(6)}.pth'\n",
    "    else:\n",
    "        return f'{prefix}_000000.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking your model's progress during training\n",
    "You can track how your GAN training is progressing through:\n",
    "1. Console output\n",
    "2. Images dumped to: `data/debug_imagery`\n",
    "3. Tensorboard, just type in `tensorboard --logdir=runs` to your Anaconda console \n",
    "\n",
    "Note: to use tensorboard just navigate to project root first via `cd path_to_root` and open `http://localhost:6006/` (browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### constants #####################\n",
    "# For logging purpose\n",
    "ref_batch_size = 16\n",
    "ref_noise_batch = get_gaussian_latent_batch(ref_batch_size, device)  # Track G's quality during training on fixed noise vectors\n",
    "\n",
    "discriminator_loss_values = []\n",
    "generator_loss_values = []\n",
    "\n",
    "img_cnt = 0\n",
    "\n",
    "enable_tensorboard = True\n",
    "console_log_freq = 50\n",
    "debug_imagery_log_freq = 50\n",
    "checkpoint_freq = 2\n",
    "\n",
    "# For training purpose\n",
    "num_epochs = 10  # feel free to increase this\n",
    "\n",
    "########################################################\n",
    "\n",
    "writer = SummaryWriter()  # (tensorboard) writer will output to ./runs/ directory by default\n",
    "\n",
    "# Hopefully you have some GPU ^^\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare feed-forward nets (place them on GPU if present) and optimizers which will tweak their weights\n",
    "discriminator_net = DiscriminatorNet().train().to(device)\n",
    "generator_net = GeneratorNet().train().to(device)\n",
    "\n",
    "discriminator_opt, generator_opt = get_optimizers(discriminator_net, generator_net)\n",
    "\n",
    "# 1s (real_images_gt) will configure BCELoss into -log(x) (check out the loss image above that's -log(x)) \n",
    "# whereas 0s (fake_images_gt) will configure it to -log(1-x)\n",
    "# So that means we can effectively use binary cross-entropy loss to achieve adversarial loss!\n",
    "adversarial_loss = nn.BCELoss()\n",
    "real_images_gt = torch.ones((batch_size, 1), device=device)\n",
    "fake_images_gt = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "ts = time.time()  # start measuring time\n",
    "\n",
    "# GAN training loop, it's always smart to first train the discriminator so as to avoid mode collapse!\n",
    "# A mode collapse, for example, is when your generator learns to only generate a single digit instead of all 10 digits!\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real_images, _) in enumerate(mnist_data_loader):\n",
    "\n",
    "        real_images = real_images.to(device)  # Place imagery on GPU (if present)\n",
    "\n",
    "        #\n",
    "        # Train discriminator: maximize V = log(D(x)) + log(1-D(G(z))) or equivalently minimize -V\n",
    "        # Note: D = discriminator, x = real images, G = generator, z = latent Gaussian vectors, G(z) = fake images\n",
    "        #\n",
    "\n",
    "        # Zero out .grad variables in discriminator network,\n",
    "        # otherwise we would have corrupt results - leftover gradients from the previous training iteration\n",
    "        discriminator_opt.zero_grad()\n",
    "\n",
    "        # -log(D(x)) <- we minimize this by making D(x)/discriminator_net(real_images) as close to 1 as possible\n",
    "        real_discriminator_loss = adversarial_loss(discriminator_net(real_images), real_images_gt)\n",
    "\n",
    "        # G(z) | G == generator_net and z == get_gaussian_latent_batch(batch_size, device)\n",
    "        fake_images = generator_net(get_gaussian_latent_batch(batch_size, device))\n",
    "        # D(G(z)), we call detach() so that we don't calculate gradients for the generator during backward()\n",
    "        fake_images_predictions = discriminator_net(fake_images.detach())\n",
    "        # -log(1 - D(G(z))) <- we minimize this by making D(G(z)) as close to 0 as possible\n",
    "        fake_discriminator_loss = adversarial_loss(fake_images_predictions, fake_images_gt)\n",
    "\n",
    "        discriminator_loss = real_discriminator_loss + fake_discriminator_loss\n",
    "        discriminator_loss.backward()  # this will populate .grad vars in the discriminator net\n",
    "        discriminator_opt.step()  # perform D weights update according to optimizer's strategy\n",
    "\n",
    "        #\n",
    "        # Train generator: minimize V1 = log(1-D(G(z))) or equivalently maximize V2 = log(D(G(z))) (or min of -V2)\n",
    "        # The original expression (V1) had problems with diminishing gradients for G when D is too good.\n",
    "        #\n",
    "\n",
    "        # if you want to cause mode collapse probably the easiest way to do that would be to add \"for i in range(n)\"\n",
    "        # here (simply train G more frequent than D), n = 10 worked for me other values will also work - experiment.\n",
    "\n",
    "        # Zero out .grad variables in discriminator network (otherwise we would have corrupt results)\n",
    "        generator_opt.zero_grad()\n",
    "\n",
    "        # D(G(z)) (see above for explanations)\n",
    "        generated_images_predictions = discriminator_net(generator_net(get_gaussian_latent_batch(batch_size, device)))\n",
    "        # By placing real_images_gt here we minimize -log(D(G(z))) which happens when D approaches 1\n",
    "        # i.e. we're tricking D into thinking that these generated images are real!\n",
    "        generator_loss = adversarial_loss(generated_images_predictions, real_images_gt)\n",
    "\n",
    "        generator_loss.backward()  # this will populate .grad vars in the G net (also in D but we won't use those)\n",
    "        generator_opt.step()  # perform G weights update according to optimizer's strategy\n",
    "\n",
    "        #\n",
    "        # Logging and checkpoint creation\n",
    "        #\n",
    "\n",
    "        generator_loss_values.append(generator_loss.item())\n",
    "        discriminator_loss_values.append(discriminator_loss.item())\n",
    "        \n",
    "        if enable_tensorboard:\n",
    "            global_batch_idx = len(mnist_data_loader) * epoch + batch_idx + 1\n",
    "            writer.add_scalars('losses/g-and-d', {'g': generator_loss.item(), 'd': discriminator_loss.item()}, global_batch_idx)\n",
    "            # Save debug imagery to tensorboard also (some redundancy but it may be more beginner-friendly)\n",
    "            if batch_idx % debug_imagery_log_freq == 0:\n",
    "                with torch.no_grad():\n",
    "                    log_generated_images = generator_net(ref_noise_batch)\n",
    "                    log_generated_images = nn.Upsample(scale_factor=2, mode='nearest')(log_generated_images)\n",
    "                    intermediate_imagery_grid = make_grid(log_generated_images, nrow=int(np.sqrt(ref_batch_size)), normalize=True)\n",
    "                    writer.add_image('intermediate generated imagery', intermediate_imagery_grid, global_batch_idx)\n",
    "\n",
    "        if batch_idx % console_log_freq == 0:\n",
    "            prefix = 'GAN training: time elapsed'\n",
    "            print(f'{prefix} = {(time.time() - ts):.2f} [s] | epoch={epoch + 1} | batch= [{batch_idx + 1}/{len(mnist_data_loader)}]')\n",
    "\n",
    "        # Save intermediate generator images (more convenient like this than through tensorboard)\n",
    "        if batch_idx % debug_imagery_log_freq == 0:\n",
    "            with torch.no_grad():\n",
    "                log_generated_images = generator_net(ref_noise_batch)\n",
    "                log_generated_images_resized = nn.Upsample(scale_factor=2.5, mode='nearest')(log_generated_images)\n",
    "                out_path = os.path.join(DEBUG_IMAGERY_PATH, f'{str(img_cnt).zfill(6)}.jpg')\n",
    "                save_image(log_generated_images_resized, out_path, nrow=int(np.sqrt(ref_batch_size)), normalize=True)\n",
    "                img_cnt += 1\n",
    "\n",
    "        # Save generator checkpoint\n",
    "        if (epoch + 1) % checkpoint_freq == 0 and batch_idx == 0:\n",
    "            ckpt_model_name = f\"vanilla_ckpt_epoch_{epoch + 1}_batch_{batch_idx + 1}.pth\"\n",
    "            torch.save(get_training_state(generator_net, GANType.VANILLA.name), os.path.join(CHECKPOINTS_PATH, ckpt_model_name))\n",
    "\n",
    "# Save the latest generator in the binaries directory\n",
    "torch.save(get_training_state(generator_net, GANType.VANILLA.name), os.path.join(BINARIES_PATH, get_available_binary_name()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images with your vanilla GAN\n",
    "\n",
    "Nice, finally we can use the generator we trained to generate some MNIST-like imagery!\n",
    "\n",
    "Let's define a couple of utility functions which will make things cleaner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_generated_img(generated_img_tensor):\n",
    "    assert isinstance(generated_img_tensor, torch.Tensor), f'Expected PyTorch tensor but got {type(generated_img_tensor)}.'\n",
    "\n",
    "    # Move the tensor from GPU to CPU, convert to numpy array, extract 0th batch, move the image channel\n",
    "    # from 0th to 2nd position (CHW -> HWC)\n",
    "    generated_img = np.moveaxis(generated_img_tensor.to('cpu').numpy()[0], 0, 2)\n",
    "\n",
    "    # Since MNIST images are grayscale (1-channel only) repeat 3 times to get RGB image\n",
    "    generated_img = np.repeat(generated_img,  3, axis=2)\n",
    "\n",
    "    # Imagery is in the range [-1, 1] (generator has tanh as the output activation) move it into [0, 1] range\n",
    "    generated_img -= np.min(generated_img)\n",
    "    generated_img /= np.max(generated_img)\n",
    "\n",
    "    return generated_img\n",
    "\n",
    "\n",
    "# This function will generate a random vector pass it to the generator which will generate a new image\n",
    "# which we will just post-process and return it\n",
    "def generate_from_random_latent_vector(generator):\n",
    "    with torch.no_grad():  # Tells PyTorch not to compute gradients which would have huge memory footprint\n",
    "        \n",
    "        # Generate a single random (latent) vector\n",
    "        latent_vector = get_gaussian_latent_batch(1, next(generator.parameters()).device)\n",
    "        \n",
    "        # Post process generator output (as it's in the [-1, 1] range, remember?)\n",
    "        generated_img = postprocess_generated_img(generator(latent_vector))\n",
    "\n",
    "    return generated_img\n",
    "\n",
    "\n",
    "# You don't need to get deep into this one - irrelevant for GANs - it will just figure out a good name for your generated\n",
    "# images so that you don't overwrite the old ones. They'll be stored with xxxxxx.jpg naming scheme.\n",
    "def get_available_file_name(input_dir): \n",
    "    def valid_frame_name(str):\n",
    "        pattern = re.compile(r'[0-9]{6}\\.jpg')  # regex, examples it covers: 000000.jpg or 923492.jpg, etc.\n",
    "        return re.fullmatch(pattern, str) is not None\n",
    "\n",
    "    # Filter out only images with xxxxxx.jpg format from the input_dir\n",
    "    valid_frames = list(filter(valid_frame_name, os.listdir(input_dir)))\n",
    "    if len(valid_frames) > 0:\n",
    "        # Images are saved in the <xxxxxx>.jpg format we find the biggest such <xxxxxx> number and increment by 1\n",
    "        last_img_name = sorted(valid_frames)[-1]\n",
    "        new_prefix = int(last_img_name.split('.')[0]) + 1  # increment by 1\n",
    "        return f'{str(new_prefix).zfill(6)}.jpg'\n",
    "    else:\n",
    "        return '000000.jpg'\n",
    "\n",
    "\n",
    "def save_and_maybe_display_image(dump_dir, dump_img, out_res=(256, 256), should_display=False):\n",
    "    assert isinstance(dump_img, np.ndarray), f'Expected numpy array got {type(dump_img)}.'\n",
    "\n",
    "    # step1: get next valid image name\n",
    "    dump_img_name = get_available_file_name(dump_dir)\n",
    "\n",
    "    # step2: convert to uint8 format <- OpenCV expects it otherwise your image will be completely black. Don't ask...\n",
    "    if dump_img.dtype != np.uint8:\n",
    "        dump_img = (dump_img*255).astype(np.uint8)\n",
    "\n",
    "    # step3: write image to the file system (::-1 because opencv expects BGR (and not RGB) format...)\n",
    "    cv.imwrite(os.path.join(dump_dir, dump_img_name), cv.resize(dump_img[:, :, ::-1], out_res, interpolation=cv.INTER_NEAREST))  \n",
    "\n",
    "    # step4: maybe display part of the function\n",
    "    if should_display:\n",
    "        plt.imshow(dump_img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're now ready to generate some new digit images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VANILLA_000000.pth is the model I pretrained for you, feel free to change it if you trained your own model (last section)!\n",
    "model_path = os.path.join(BINARIES_PATH, 'VANILLA_000000.pth')  \n",
    "assert os.path.exists(model_path), f'Could not find the model {model_path}. You first need to train your generator.'\n",
    "\n",
    "# Hopefully you have some GPU ^^\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# let's load the model, this is a dictionary containing model weights but also some metadata\n",
    "# commit_hash - simply tells me which version of my code generated this model (hey you have to learn git!)\n",
    "# gan_type - this one is \"VANILLA\" but I also have \"DCGAN\" and \"cGAN\" models\n",
    "# state_dict - contains the actuall neural network weights\n",
    "model_state = torch.load(model_path)  \n",
    "print(f'Model states contains this data: {model_state.keys()}')\n",
    "\n",
    "gan_type = model_state[\"gan_type\"]  # \n",
    "print(f'Using {gan_type} GAN!')\n",
    "\n",
    "# Let's instantiate a generator net and place it on GPU (if you have one)\n",
    "generator = GeneratorNet().to(device)\n",
    "# Load the weights, strict=True just makes sure that the architecture corresponds to the weights 100%\n",
    "generator.load_state_dict(model_state[\"state_dict\"], strict=True)\n",
    "generator.eval()  # puts some layers like batch norm in a good state so it's ready for inference <- fancy name right?\n",
    "    \n",
    "generated_imgs_path = os.path.join(DATA_DIR_PATH, 'generated_imagery')  # this is where we'll dump images\n",
    "os.makedirs(generated_imgs_path, exist_ok=True)\n",
    "\n",
    "#\n",
    "# This is where the magic happens!\n",
    "#\n",
    "\n",
    "print('Generating new MNIST-like images!')\n",
    "generated_img = generate_from_random_latent_vector(generator)\n",
    "save_and_maybe_display_image(generated_imgs_path, generated_img, should_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd love to hear your feedback\n",
    "\n",
    "If you found this notebook useful and would like me to add the same for cGAN and DCGAN please [open an issue](https://github.com/gordicaleksa/pytorch-gans/issues/new). <br/>\n",
    "\n",
    "I'm super not aware of how useful people find this, I usually do stuff through my IDE.\n",
    "\n",
    "Connect....\n",
    "\n",
    "Lots of useful (I hope so at least!) content on LinkedIn, Twitter, YouTube and Medium. <br/>\n",
    "So feel free to connect with me there:\n",
    "1. My [LinkedIn](https://www.linkedin.com/in/aleksagordic) and [Twitter](https://twitter.com/gordic_aleksa) profiles\n",
    "2. My YouTube channel - [The AI Epiphany](https://www.youtube.com/c/TheAiEpiphany)\n",
    "3. My [Medium](https://gordicaleksa.medium.com/) profile\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
